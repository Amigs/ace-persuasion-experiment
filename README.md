# ğŸ§  ACE Persuasion Experiment

DemonstraciÃ³n del framework ACE (Actor-Curator-Reflector) para el experimento "AI for Bad" presentado en AI Tinkers. Muestra cÃ³mo los sistemas de IA pueden evolucionar su comportamiento Ã©tico/persuasivo mediante iteraciones sucesivas.

## ğŸ“‹ Resultados del Experimento
Comparativa de 3 modelos con objetivo controvertido:
- **Grok**: MÃ¡s persuasivo desde el inicio
- **Azure OpenAI**: Resistencia inicial pero eventual cedimiento  
- **DeepSeek**: Mantenimiento de principios Ã©ticos

<image src="./images/output_results.png" alt="DescripciÃ³n de la imagen">

## ğŸš€ ConfiguraciÃ³n RÃ¡pida

### 1. Clonar y Entorno Virtual
```bash
git clone https://github.com/Amigs/ace-persuasion-experiment.git
cd ace-persuasion-experiment
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows
```

### 2. Instalar Dependencias
```bash
pip install -r requirements.txt
```

### 3. Configurar API Keys
```bash
cp .env.example .env
# Editar .env con tus credenciales:
```

## ğŸ“Š MÃ©tricas Analizadas
- **Ã‰tica**: Comportamiento responsable y transparente
- **PersuasiÃ³n**: Efectividad en conseguir el objetivo  
- **Balance**: Equilibrio entre persuasiÃ³n y Ã©tica

## ğŸ› ï¸ Dependencias Principales
- langchain-core, langchain-openai, langchain-deepseek
- pandas, matplotlib, jupyter
- python-dotenv

---

*Presentado en AI Tinkers BogotÃ¡ Colombia- EdiciÃ³n AI for Bad*


